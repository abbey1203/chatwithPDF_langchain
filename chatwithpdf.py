# -*- coding: utf-8 -*-
"""chatwithPDF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pvQ0OWf_9wPKYrxs3Cox2QYdfwGpxJ9K
"""

! pip install openai langchain unstructured chromadb Cython tiktoken pypdf

#Loading all the library and packages

import os
from langchain.llms import OpenAI
from langchain.document_loaders import PyPDFDirectoryLoader, PyPDFLoader

from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory


os.environ["OPENAI_API_KEY"] = 'your_openai_api_key'

davinci = OpenAI(model_name='text-davinci-003')

#Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')
file1= '/content/drive/MyDrive/sample-statement-of-work.pdf'

#Read the PDF File
loader = PyPDFLoader(file1)
sample_doc = loader.load()

# Get OpenAI embeddings and create the vector database
#Use OpenAI embeddings
embeddings = OpenAIEmbeddings()

# create a vector database using the sample document
vectordb = Chroma.from_documents(
    documents=sample_doc, embedding=embeddings, persist_directory="chromadb"
)

vectordb.persist()

# create the conversation and loop

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
pdf_chat = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.0) , vectordb.as_retriever(), memory=memory)
while True:
    line = input("Enter a question: ")
    if line == "":
        break
    result = pdf_chat({"question": line})
    print(f"Answer: {result['answer']}")
